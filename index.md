I am a fifth year Computer Science PhD in the [MURGe Lab](https://murgelab.cs.unc.edu/) (part of the bigger [UNC NLP Lab](https://nlp.cs.unc.edu/)) at the University of North Carolina at Chapel Hill, advised by [Prof. Mohit Bansal](http://www.cs.unc.edu/~mbansal/). My PhD is supported by a [Google PhD Fellowship](https://research.google/outreach/phd-fellowship/recipients/) and a Rebecca and Munroe Cobey Fellowship.

I study Machine Learning and NLP. I am generally interested in developing interpretable ML methods that enable language agents to solve complex, multi-step reasoning problems, often referred to as the [System 2 Reasoning](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow#:~:text=Thinking%2C%20Fast%20and%20Slow%20is,book%20by%20psychologist%20Daniel%20Kahneman.&text=The%20book's%20main%20thesis%20is,more%20deliberative%2C%20and%20more%20logical.). In the past, I have developed models that can generate Natural Language Proofs for formal reasoning ([EMNLP 2020](https://arxiv.org/abs/2010.02830), [NAACL 2021](https://arxiv.org/abs/2106.01354)), Explanation Graphs for structured commonsense reasoning ([EMNLP 2021](https://arxiv.org/abs/2104.07644), [ACL 2022](https://arxiv.org/abs/2204.04813)), and Summarization Programs for abstractive summarization ([ICLR 2023](https://arxiv.org/abs/2209.10492), [ACL 2023](https://arxiv.org/abs/2212.08607)). My current research focus is understanding how LLMs reason and the role of explanations in multi-agent environments ([NeurIPS 2023](https://arxiv.org/abs/2306.09299), [arXiv 2023](https://arxiv.org/abs/2309.13007)]. Once I wrote a paper connecting explainability to data hardness ([EMNLP 2022](https://arxiv.org/abs/2211.07517)). During my PhD, I have spent three wonderful summers, twice interning at [FAIR Labs, Meta AI](https://ai.facebook.com/) and once at [Salesforce AI Research](https://www.salesforceairesearch.com/).

Before starting my PhD, I was a Research Engineer at [IBM Research - India](https://www.research.ibm.com/labs/india/) building industry-scale Intelligent Tutoring Systems. Even before that, I did my M.Tech. in CS from IIT, Delhi, having worked with [Prof. Mausam](http://www.cse.iitd.ac.in/~mausam/) and developed the state-of-the-art Open Information Extraction system ([Open IE 5.0](https://github.com/dair-iitd/OpenIE-standalone)) (ACL 2017, COLING 2018).

## Recent News

* **September 2023**: New pre-print out! [Diverse LLMs improve reasoning via multi-round discussion and convincing each other](https://arxiv.org/abs/2309.13007).
* **September 2023**: [Can Language Models Teach Weaker Agents](https://arxiv.org/abs/2306.09299) is accepted to NeurIPS 2023.
* **June 2023**: New pre-print on [Can Language Models Teach Weaker Agents](https://arxiv.org/abs/2306.09299) out on arXiv.
* **May 2023**: Started Internship at FAIR Labs, hosted by [Xian Li](https://ai.facebook.com/people/xian-li/) and [Omer Levy](http://www.cs.tau.ac.il/~levyomer/).  
* **May 2023**: [MURMUR](https://arxiv.org/abs/2212.08607) is accepted to [ACL Findings](https://2023.aclweb.org/).  
* **April 2023**: New pre-print on Evaluating Reasoning Chains on [arXiv](https://arxiv.org/abs/2304.10703).   
* **January 2023**: [Summarization Programs](https://arxiv.org/abs/2209.10492) is accepted to [ICLR 2023](https://iclr.cc/).  

## Industry Experience

* Research Intern (with [Xian Li](https://ai.facebook.com/people/xian-li/), [Omer Levy](http://www.cs.tau.ac.il/~levyomer/), [Jason Weston](https://ai.meta.com/people/jason-weston/), [Asli Celikyilmaz](http://asli.us/)), [FAIR Labs, Meta AI](https://ai.facebook.com/) (Summer 2023)
* Research Intern (with [Asli Celikyilmaz](http://asli.us/)), [FAIR Labs, Meta AI](https://ai.facebook.com/) (Summer 2022)
* Research Intern (with [Nazneen Rajani](http://www.nazneenrajani.com/)), [Salesforce AI Research](https://www.salesforceairesearch.com/) (Summer 2021)
* Research Engineer, [IBM Research](https://www.research.ibm.com/labs/india/) (2017-2019)
* Member of Technical Staff, [Adobe Systems](https://www.adobe.com/in/) (2014-2015)

## Selected Publications [[Google Scholar](https://scholar.google.co.in/citations?user=sY5SyBgAAAAJ&hl=en)] [[dblp](https://dblp.uni-trier.de/pers/hd/s/Saha:Swarnadeep)]

* **ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs**  
Justin Chih-Yao Chen, **Swarnadeep Saha**, and Mohit Bansal   
Pre-print on arXiv, 2023      
[Long] [[paper](https://arxiv.org/abs/2309.13007)] [[code](https://github.com/dinobby/ReConcile)]

* **ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness**  
Archiki Prasad, **Swarnadeep Saha**, Xiang Zhou, and Mohit Bansal  
Pre-print on arXiv, 2023  
[Long] [[paper](https://arxiv.org/abs/2304.10703)] [[code](https://github.com/archiki/ReCEval)] 

* **Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind**  
**Swarnadeep Saha**, Peter Hase, and Mohit Bansal   
[Neural Information Processing Systems](https://nips.cc/) (**NeurIPS**), 2023      
[Long] [Poster] [[paper](https://arxiv.org/abs/2306.09299)] [[code](https://github.com/swarnaHub/ExplanationIntervention)] 

* **MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation**  
**Swarnadeep Saha**, Xinyan Velocity Yu, Mohit Bansal, Ramakanth Pasunuru, and Asli Celikyilmaz  
[Annual Meeting of the Association for Computational Linguistics](https://www.2023.aclweb.org/) (**Findings of ACL**), 2023    
[Long] [Poster] [[paper](https://arxiv.org/abs/2212.08607)] [[code]()] 

* **Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees**  
**Swarnadeep Saha**, Shiyue Zhang, Peter Hase, and Mohit Bansal   
[International Conference on Learning Representations](https://iclr.cc/) (**ICLR**) 2023     
[Long] [Poster] [[paper](https://arxiv.org/abs/2209.10492)] [[code](https://github.com/swarnaHub/SummarizationPrograms)] 

* **Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations**  
**Swarnadeep Saha**, Peter Hase, Nazneen Rajani, and Mohit Bansal   
[Conference on Empirical Methods in Natural Language Processing](https://2022.emnlp.org/) (**EMNLP**), 2022      
[Short] [Oral] [[paper](https://arxiv.org/abs/2211.07517)] [[data](https://github.com/swarnaHub/ExplanationHardness)] 

* **Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning** [Accept Rate: 21%]     
**Swarnadeep Saha**, Prateek Yadav, and Mohit Bansal  
[Annual Meeting of the Association for Computational Linguistics](https://www.2022.aclweb.org/) (**ACL**), 2022     
[Long] [Poster] [[paper](https://arxiv.org/abs/2204.04813)] [[code](https://github.com/swarnaHub/ExplagraphGen)]    

* **ExplaGraphs: An Explanation Graph Generation Task for Structured Commonsense Reasoning** [Acceptance Rate: 23%]      
**Swarnadeep Saha**, Prateek Yadav, Lisa Bauer, and Mohit Bansal  
[Conference on Empirical Methods in Natural Language Processing](https://2021.emnlp.org/) (**EMNLP**), 2021     
[Long] [Oral] [[paper](https://arxiv.org/abs/2104.07644)] [[data/code](https://github.com/swarnaHub/ExplaGraphs)] [[website](https://explagraphs.github.io/)]

* **multiPRover: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning** [Acceptance Rate: 26%]   
**Swarnadeep Saha**, Prateek Yadav, and Mohit Bansal  
[Conference of the North American Chapter of the Association for Computational Linguistics](https://2021.naacl.org/) (**NAACL**), 2021     
[Long] [Oral] [[paper](https://arxiv.org/abs/2106.01354)] [[code](https://github.com/swarnaHub/multiPRover)]

* **PRover: Proof Generation for Interpretable Reasoning over Rules** [Acceptance Rate: 22%]  
**Swarnadeep Saha**, Sayan Ghosh, Shashank Srivastava, and Mohit Bansal  
[Conference on Empirical Methods in Natural Language Processing](https://2020.emnlp.org/) (**EMNLP**), 2020  
[Long] [Oral] [[paper](https://arxiv.org/abs/2010.02830)] [[code](https://github.com/swarnaHub/PRover)]

* **ConjNLI: Natural Language Inference over Conjunctive Sentences** [Acceptance Rate: 22%]   
**Swarnadeep Saha**, Yixin Nie, and Mohit Bansal  
[Conference on Empirical Methods in Natural Language Processing](https://2020.emnlp.org/) (**EMNLP**), 2020  
[Long] [Poster] [[paper](https://arxiv.org/abs/2010.10418)] [[data/code](https://github.com/swarnaHub/ConjNLI)]

* **Pre-Training BERT on Domain Resources for Short Answer Grading** [Acceptance Rate: 23%]  
Chul Sung, Tejas Dhamecha, **Swarnadeep Saha**, Tengfei Ma, Vinay Reddy, and Rishi Arora  
[Conference on Empirical Methods in Natural Language Processing](http://emnlp-ijcnlp2019.org/) (**EMNLP-IJCNLP**), 2019  
[Short] [Poster] [[paper](https://swarnahub.github.io/papers/EMNLP19.pdf)]  

* **Aligning Learning Objectives to Learning Resources: A Lexico-Semantic Spatial Approach** [Acceptance Rate: 17%]  
**Swarnadeep Saha**, Malolan Chetlur, Tejas Indulal Dhamecha, W M Gayathri K Wijayarathna, Red Mendoza, Paul Gagnon, Nabil Zary, and Shantanu Godbole  
[28th International Joint Conference on Artificial Intelligence](https://www.ijcai19.org/) (**IJCAI**), 2019  
[Long] [Oral+Poster] [[paper](https://swarnahub.github.io/papers/IJCAI19.pdf)]  

* **Creating Scoring Rubric from Representative Student Answers for Improved Short Answer Grading**  [Acceptance Rate: 17%]  
Smit Marvaniya, **Swarnadeep Saha**, Tejas I. Dhamecha, Peter Foltz, Renuka Sindhgatta, and Bikram Sengupta  
[27th ACM International Conference on Information and Knowledge Management](https://www.cikm2018.units.it/) (**CIKM**), 2018  
[Long] [Oral] [[paper](https://swarnahub.github.io/papers/CIKM18.pdf)]

* **Open Information Extraction from Conjunctive Sentences** [Acceptance Rate: 37%]  
**Swarnadeep Saha**, and Mausam  
[27th International Conference on Computational Linguistics](https://coling2018.org/) (**COLING**), 2018  
[Long] [Oral] [[paper](https://swarnahub.github.io/papers/COLING18.pdf)] [[code](https://github.com/dair-iitd/OpenIE-standalone)] [[slides](https://swarnahub.github.io/papers/COLING18Slides.pptx)]

* **Sentence Level or Token Level Features for Automatic Short Answer Grading?: Use Both** [Acceptance Rate: 25%]  
**Swarnadeep Saha**, Tejas I. Dhamecha, Smit Marvaniya, Renuka Sindhgatta, and Bikram Sengupta  
[19th International Conference of AI in Education](https://aied2018.utscic.edu.au/) (**AIED**), 2018   
[Long] [Oral] [[paper](https://swarnahub.github.io/papers/AIED18a.pdf)] [[slides](https://swarnahub.github.io/papers/AIED18aSlides.pptx)]

* **Balancing Human Efforts and Performance of Student Response Analyzer in Dialog-based Tutors** [Acceptance Rate: 25%]  
Tejas I. Dhamecha, Smit Marvaniya, **Swarnadeep Saha**, Renuka Sindhgatta, and Bikram Sengupta  
[19th International Conference of AI in Education](https://aied2018.utscic.edu.au/) (**AIED**), 2018  
[Long] [Oral] [[paper](https://swarnahub.github.io/papers/AIED18b.pdf)] [[slides](https://swarnahub.github.io/papers/AIED18bSlides.pptx)]

* **Bootstrapping for Numerical Open IE** [Acceptance Rate: 18%]  
**Swarnadeep Saha**, Harinder Pal, and Mausam  
[55th Annual Meeting of the Association for Computational Linguistics](http://acl2017.org/) (**ACL**), 2017  
[Short] [Poster] [[paper](https://swarnahub.github.io/papers/ACL17.pdf)] [[code](https://github.com/dair-iitd/OpenIE-standalone)] [[poster](https://swarnahub.github.io/papers/ACL17Poster.pdf)] 

## Teaching

* [COL 774: Machine Learning - Spring 2016](http://www.cse.iitd.ac.in/~parags/teaching/2017/sp17/col774/)  
Instructor: [Prof. Parag Singla](http://www.cse.iitd.ac.in/~parags/teaching.html)

* [COL 333/COL 671: Artificial Intelligence - Fall 2016](http://www.cse.iitd.ac.in/~mausam/courses/col333/autumn2016/)  
Instructor: [Prof. Mausam](http://www.cse.iitd.ac.in/~mausam/)

## Awards

* Google PhD Fellowship in Natural Language Processing (2022).
* Munroe and Rebecca Cobey fellowship award at UNC (2019). 
* Research appreciation award by director of IBM Research India for contributions to Watson Tutor (2018).
* Manager's choice award at IBM Research - India for research contributions (2018).
* Best Masters thesis award at IIT Delhi (2017).

## Professional Service

* Reviewer for EMNLP 2022, ARR 2022, ARR 2021, EMNLP 2021, AIJ 2021, NAACL 2021, AAAI 2020, AIED 2019, NAACL 2019, EMNLP 2018.
